{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 1, due March 1 by midnight\n",
    "\n",
    "The goal of this problem set is to replicate and extend the results of  Jean et al.'s 2016 paper, \"Combining satellite imagery and machine learning to predict poverty.\" This problem set will be challenging and time-consuming, so I suggest you start immediately. Your first step should be to carefully read <a href=\"https://pdfs.semanticscholar.org/1b3a/c4b4187a3dbc9373869e7774b1dc63f748d2.pdf\">the original paper</a>  as well as the <a href=\"http://science.sciencemag.org/content/sci/suppl/2016/08/19/353.6301.790.DC1/Jean.SM.pdf\">supplementary materials</a>.\n",
    "\n",
    "For this assignment, we will focus on the country of Rwanda. You will need to download three distinct datasets, including DHS data, satellite data from the Google Maps API, as well as nighttime luminosity data. The DHS data requires registration (which can take several days to be approved), and the Google Maps API is rate-limited, so it will necessarily take you several days to download the requisite data, so make sure to **get started on those steps asap**. The deep learning section may also take several hours to compute (or days, if you have a slow computer), so don't save it until the last minute.\n",
    "\n",
    "## Overview of the problem set\n",
    "\n",
    "These are the key steps in the problem set:\n",
    "\n",
    "1. Download satellite night lights images from NOAA\n",
    "2. Download DHS data for Rwanda\n",
    "3. Test whether night lights data can predict wealth, as observed in DHS\n",
    "4. Download daytime satellite imagery from Google Maps\n",
    "5. Test whether basic features of daytime imagery can predict wealth\n",
    "6. Extract features from daytime imagery using deep learning libraries\n",
    "7. Replicate final model and results of Jean et al (2016)\n",
    "8. Construct maps showing the predicted distribution of wealth in Rwanda\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Download nightlights for Rwanda\n",
    "\n",
    "- **INPUT**:\n",
    " - None\n",
    "- **OUTPUT**: \n",
    " - `F182010.v4d_web.stable_lights.avg_vis.tif`: Single image file giving nightlights intensity around the world\n",
    "\n",
    "Go to the [DMSP-OLS website](https://ngdc.noaa.gov/eog/dmsp/downloadV4composites.html) and download the satellite nighttime luminosity data (roughly 400MB). We will use the one from 2010. The archive they provide constains several files. Feel free to explore these files. We will only be using the file F182010.v4d_web.stable_lights.avg_vis.tif.\n",
    "\n",
    "A code snippet to get you started is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import wget\n",
    "\n",
    "night_image_url = 'https://ngdc.noaa.gov/eog/data/web_data/v4composites/F182010.v4.tar'\n",
    "tar = wget.download(night_image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F182010.v4d_web.avg_vis.tif.gz\n",
      "F182010.v4d_web.cf_cvg.tif.gz\n",
      "F182010.v4d_web.stable_lights.avg_vis.tif.gz\n",
      "README_V4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘nightlights’: File exists\n",
      "gzip: nightlights/F182010.v4d_web.stable_lights.avg_vis.tif already exists;\tnot overwritten\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "mkdir nightlights\n",
    "tar -zxvf F182010.v4.tar -C nightlights/\n",
    "gzip -d nightlights/F182010.v4d_web.stable_lights.avg_vis.tif.gz\n",
    "rm nightlights/*.gz\n",
    "mv F182010.v4.tar nightlights/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Download Rwandan DHS and construct cluster-level aggregates\n",
    "\n",
    "- **INPUT**: \n",
    "  - `rwanda_clusters_location.csv`: Coordinates of the centroid of each cluster\n",
    "- **OUTPUT**: \n",
    "  - `rwanda_cluster_avg_asset_2010.csv`: Comma-delimited file indicated average wealth of each cluster \n",
    "\n",
    "[Demographic and Health Surveys (DHS)](http://dhsprogram.com/What-We-Do/Survey-Types/DHS.cfm) are nationally-representative household surveys that provide data for a wide range of monitoring and impact evaluation indicators in the areas of population, health, and nutrition. For this assignment, you will need to download the [2010 Rwandan DHS data](http://dhsprogram.com/what-we-do/survey/survey-display-364.cfm). **This requires registration, so start early!** Do not forget to request for the GPS dataset. Make sure you understand the structure of the data before starting.\n",
    "\n",
    "Your immediate goal is to take the raw survey data, covering 12,540 households, and compute the average household wealth for each survey cluster (think of a cluster as a village). Refer to the file `Recode6_DHS_22March2013_DHSG4.pdf` for information on these data.\n",
    "\n",
    "Save your output as `rwanda_cluster_avg_asset_2010.csv` and check that it matches the file that we have provided. You will use this file as input to the next step in the assignment.\n",
    "\n",
    "Hints:\n",
    "- `Household Recode` contains all the attributes of each household. It provides datasets with different formats. Feel free to explore the data. You can use `RWHR61FL.DAT` file in Flat ASCII data (.dat) format.\n",
    "- `RWHR61FL.DCF` describes the attributes and the location of each attribute.\n",
    "- Geographic Datasets: `rwge61fl.zip` contains the location of each cluster in Rwanda. It is in the format of shapefile, which needs QGIS or other GIS softwares to open. For those who are not familiar with GIS tools or who want a shortcut, you can also sue the file `rwanda_clusters_location.csv` provided with the problem set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, the cluster locations, overlaid on the nightlights data, are shown in the figure below.\n",
    "<img src=\"figure/map1.png\" alt=\"Map\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>DHSID</th>\n",
       "      <th>DHSCC</th>\n",
       "      <th>DHSYEAR</th>\n",
       "      <th>DHSCLUST</th>\n",
       "      <th>CCFIPS</th>\n",
       "      <th>ADM1FIPS</th>\n",
       "      <th>ADM1FIPSNA</th>\n",
       "      <th>ADM1SALBNA</th>\n",
       "      <th>...</th>\n",
       "      <th>ADM1NAME</th>\n",
       "      <th>DHSREGCO</th>\n",
       "      <th>DHSREGNA</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>URBAN_RURA</th>\n",
       "      <th>LATNUM</th>\n",
       "      <th>LONGNUM</th>\n",
       "      <th>ALT_GPS</th>\n",
       "      <th>ALT_DEM</th>\n",
       "      <th>DATUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.684726</td>\n",
       "      <td>-2.532818</td>\n",
       "      <td>RW201000000001</td>\n",
       "      <td>RW</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>RW</td>\n",
       "      <td>RW15</td>\n",
       "      <td>Southern</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>South</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Huye</td>\n",
       "      <td>GPS</td>\n",
       "      <td>R</td>\n",
       "      <td>-2.532818</td>\n",
       "      <td>29.684726</td>\n",
       "      <td>1706.0</td>\n",
       "      <td>1702.0</td>\n",
       "      <td>WGS84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.310689</td>\n",
       "      <td>-1.833858</td>\n",
       "      <td>RW201000000002</td>\n",
       "      <td>RW</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>RW</td>\n",
       "      <td>RW11</td>\n",
       "      <td>Eastern</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>East</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Gatsibo</td>\n",
       "      <td>GPS</td>\n",
       "      <td>R</td>\n",
       "      <td>-1.833858</td>\n",
       "      <td>30.310689</td>\n",
       "      <td>1631.0</td>\n",
       "      <td>1631.0</td>\n",
       "      <td>WGS84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.478298</td>\n",
       "      <td>-1.888155</td>\n",
       "      <td>RW201000000003</td>\n",
       "      <td>RW</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>RW</td>\n",
       "      <td>RW14</td>\n",
       "      <td>Western</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>West</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Ngororero</td>\n",
       "      <td>GPS</td>\n",
       "      <td>R</td>\n",
       "      <td>-1.888155</td>\n",
       "      <td>29.478298</td>\n",
       "      <td>2310.0</td>\n",
       "      <td>2324.0</td>\n",
       "      <td>WGS84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.521692</td>\n",
       "      <td>-2.366763</td>\n",
       "      <td>RW201000000004</td>\n",
       "      <td>RW</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>RW</td>\n",
       "      <td>RW11</td>\n",
       "      <td>Eastern</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>East</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Kirehe</td>\n",
       "      <td>GPS</td>\n",
       "      <td>R</td>\n",
       "      <td>-2.366763</td>\n",
       "      <td>30.521692</td>\n",
       "      <td>1388.0</td>\n",
       "      <td>1399.0</td>\n",
       "      <td>WGS84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.018541</td>\n",
       "      <td>-2.171266</td>\n",
       "      <td>RW201000000005</td>\n",
       "      <td>RW</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>RW</td>\n",
       "      <td>RW11</td>\n",
       "      <td>Eastern</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>East</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Bugesera</td>\n",
       "      <td>GPS</td>\n",
       "      <td>R</td>\n",
       "      <td>-2.171266</td>\n",
       "      <td>30.018541</td>\n",
       "      <td>1437.0</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>WGS84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X         Y           DHSID DHSCC  DHSYEAR  DHSCLUST CCFIPS  \\\n",
       "0  29.684726 -2.532818  RW201000000001    RW   2010.0       1.0     RW   \n",
       "1  30.310689 -1.833858  RW201000000002    RW   2010.0       2.0     RW   \n",
       "2  29.478298 -1.888155  RW201000000003    RW   2010.0       3.0     RW   \n",
       "3  30.521692 -2.366763  RW201000000004    RW   2010.0       4.0     RW   \n",
       "4  30.018541 -2.171266  RW201000000005    RW   2010.0       5.0     RW   \n",
       "\n",
       "  ADM1FIPS ADM1FIPSNA  ADM1SALBNA  ...    ADM1NAME  DHSREGCO   DHSREGNA  \\\n",
       "0     RW15   Southern         NaN  ...       South       7.0       Huye   \n",
       "1     RW11    Eastern         NaN  ...        East      26.0    Gatsibo   \n",
       "2     RW14    Western         NaN  ...        West      16.0  Ngororero   \n",
       "3     RW11    Eastern         NaN  ...        East      28.0     Kirehe   \n",
       "4     RW11    Eastern         NaN  ...        East      30.0   Bugesera   \n",
       "\n",
       "   SOURCE URBAN_RURA    LATNUM    LONGNUM  ALT_GPS  ALT_DEM  DATUM  \n",
       "0     GPS          R -2.532818  29.684726   1706.0   1702.0  WGS84  \n",
       "1     GPS          R -1.833858  30.310689   1631.0   1631.0  WGS84  \n",
       "2     GPS          R -1.888155  29.478298   2310.0   2324.0  WGS84  \n",
       "3     GPS          R -2.366763  30.521692   1388.0   1399.0  WGS84  \n",
       "4     GPS          R -2.171266  30.018541   1437.0   1445.0  WGS84  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "clusters = pd.read_csv('provided/rwanda_clusters_location.csv')\n",
    "clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>578</th>\n",
       "      <th>579</th>\n",
       "      <th>580</th>\n",
       "      <th>581</th>\n",
       "      <th>582</th>\n",
       "      <th>583</th>\n",
       "      <th>584</th>\n",
       "      <th>585</th>\n",
       "      <th>586</th>\n",
       "      <th>587</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12115RW6</td>\n",
       "      <td>121</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>121</td>\n",
       "      <td>737365</td>\n",
       "      <td>220111334</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12119RW6</td>\n",
       "      <td>121</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>737365</td>\n",
       "      <td>320111335</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12121RW6</td>\n",
       "      <td>121</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>121</td>\n",
       "      <td>737365</td>\n",
       "      <td>220111334</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12116RW6</td>\n",
       "      <td>121</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>121</td>\n",
       "      <td>737365</td>\n",
       "      <td>220111334</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121</td>\n",
       "      <td>3RW6</td>\n",
       "      <td>121</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>121</td>\n",
       "      <td>737365</td>\n",
       "      <td>220111334</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 588 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1    2   3    4       5          6          7   8   9    ...   \\\n",
       "0  12115RW6   121   15   2  121  737365  220111334          7   3   1  ...    \n",
       "1  12119RW6   121   19   1  121  737365  320111335          1   0   0  ...    \n",
       "2  12121RW6   121   21   2  121  737365  220111334          5   1   2  ...    \n",
       "3  12116RW6   121   16   2  121  737365  220111334          3   2   0  ...    \n",
       "4       121  3RW6  121   3    2     121     737365  220111334   6   1  ...    \n",
       "\n",
       "    578   579   580   581   582   583   584   585   586   587  \n",
       "0  None  None  None  None  None  None  None  None  None  None  \n",
       "1  None  None  None  None  None  None  None  None  None  None  \n",
       "2  None  None  None  None  None  None  None  None  None  None  \n",
       "3  None  None  None  None  None  None  None  None  None  None  \n",
       "4  None  None  None  None  None  None  None  None  None  None  \n",
       "\n",
       "[5 rows x 588 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert .dat to dataframe with magic\n",
    "# https://stackoverflow.com/questions/27413843/difficulty-importing-dat-file\n",
    "with open('rwandan-dhs/RWHR61FL.DAT','r') as f:\n",
    "    dhs = pd.DataFrame(l.rstrip().split() for l in f)\n",
    "\n",
    "dhs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO for each cluster, \n",
    "#      find the mean househould income of all homes in that cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Test whether night lights data can predict wealth, as observed in DHS\n",
    "\n",
    "Now that you have \"ground truth\" measures of average cluster wealth, your goal is to understand whether the nightlights data can be used to predict wealth. First, merge the DHS and nightlights data, and then fit a model of wealth on nightlights.\n",
    "\n",
    "## 3.1 Merge nightlights and DHS data at cluster level\n",
    "- **INPUT**: \n",
    " - `F182010.v4d_web.stable_lights.avg_vis.tif`: Nightlights data, from Step 1\n",
    " - `rwanda_cluster_avg_asset_2010.csv`: DHS cluster averages, from Step 2\n",
    "- **OUTPUT**: Merged datasets\n",
    " - `DHS_nightlights.csv`: Merged dataset with 492 rows, and 6 columns (one indicates average cluster wealth, 5 nightlights features)\n",
    " - Scatterplot of nightlights vs. DHS wealth\n",
    "\n",
    "Perform a \"spatial join\" to compute the average nighttime luminosity for each of the DHS clusters. To do this, you should take the average of the luminosity values for the nightlights locations surrounding the cluster centroid.\n",
    "\n",
    "Save your output as `DHS_nightlights.csv` and check that it is the same as the file we have provided.\n",
    "\n",
    "Create a scatterplot showing the relationship between average cluster wealth (y-axis) and average nighttime luminosity (x-axis). Your scatterplot should have one dot for each of the 492 DHS clusters. Report the R^2 of the regression line.\n",
    "\n",
    "Hints:\n",
    " - The resolution of each pixel in the nightlight image is about 1km. Use 10 pixels X 10 pixels to average the luminosity of each cluster.\n",
    " - Start by just taking the **Mean** of the luminosity in the 100 pixels and comparing this to cluster average wealth. If you like, you could also compute other luminosity characteristics of each cluster, such as the **Max**, **Min**, **Standard Deviation** of the 100 pixel values, but this step is not required. Note that the file we provide (`DHS_nightlights.csv`) has these added features.\n",
    " - To read the raw raster (nightlights) files, we recommend using the GDAL library. Use `conda install gdal` to install the GDAL library. We have provided some helper code for this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import os.path\n",
    "from osgeo import gdal, ogr, osr\n",
    "from scipy import ndimage\n",
    "from scipy import misc\n",
    "import cStringIO\n",
    "gdal.UseExceptions()\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "%matplotlib inline\n",
    "import urllib\n",
    "\n",
    "# Helper function to read a raster file\n",
    "def read_raster(raster_file):\n",
    "    \"\"\"\n",
    "    Function\n",
    "    --------\n",
    "    read_raster\n",
    "\n",
    "    Given a raster file, get the pixel size, pixel location, and pixel value\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raster_file : string\n",
    "        Path to the raster file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x_size : float\n",
    "        Pixel size\n",
    "    top_left_x_coords : numpy.ndarray  shape: (number of columns,)\n",
    "        Longitude of the top-left point in each pixel\n",
    "    top_left_y_coords : numpy.ndarray  shape: (number of rows,)\n",
    "        Latitude of the top-left point in each pixel\n",
    "    centroid_x_coords : numpy.ndarray  shape: (number of columns,)\n",
    "        Longitude of the centroid in each pixel\n",
    "    centroid_y_coords : numpy.ndarray  shape: (number of rows,)\n",
    "        Latitude of the centroid in each pixel\n",
    "    bands_data : numpy.ndarray  shape: (number of rows, number of columns, 1)\n",
    "        Pixel value\n",
    "    \"\"\"\n",
    "    raster_dataset = gdal.Open(raster_file, gdal.GA_ReadOnly)\n",
    "    # get project coordination\n",
    "    proj = raster_dataset.GetProjectionRef()\n",
    "    bands_data = []\n",
    "    # Loop through all raster bands\n",
    "    for b in range(1, raster_dataset.RasterCount + 1):\n",
    "        band = raster_dataset.GetRasterBand(b)\n",
    "        bands_data.append(band.ReadAsArray())\n",
    "        no_data_value = band.GetNoDataValue()\n",
    "    bands_data = np.dstack(bands_data)\n",
    "    rows, cols, n_bands = bands_data.shape\n",
    "\n",
    "    # Get the metadata of the raster\n",
    "    geo_transform = raster_dataset.GetGeoTransform()\n",
    "    (upper_left_x, x_size, x_rotation, upper_left_y, y_rotation, y_size) = geo_transform\n",
    "    \n",
    "    # Get location of each pixel\n",
    "    x_size = 1.0 / int(round(1 / float(x_size)))\n",
    "    y_size = - x_size\n",
    "    y_index = np.arange(bands_data.shape[0])\n",
    "    x_index = np.arange(bands_data.shape[1])\n",
    "    top_left_x_coords = upper_left_x + x_index * x_size\n",
    "    top_left_y_coords = upper_left_y + y_index * y_size\n",
    "    # Add half of the cell size to get the centroid of the cell\n",
    "    centroid_x_coords = top_left_x_coords + (x_size / 2)\n",
    "    centroid_y_coords = top_left_y_coords + (y_size / 2)\n",
    "\n",
    "    return (x_size, top_left_x_coords, top_left_y_coords, centroid_x_coords, centroid_y_coords, bands_data)\n",
    "\n",
    "\n",
    "# Helper function to get the pixel index of the point\n",
    "def get_cell_idx(lon, lat, top_left_x_coords, top_left_y_coords):\n",
    "    \"\"\"\n",
    "    Function\n",
    "    --------\n",
    "    get_cell_idx\n",
    "\n",
    "    Given a point location and all the pixel locations of the raster file,\n",
    "    get the column and row index of the point in the raster\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lon : float\n",
    "        Longitude of the point\n",
    "    lat : float\n",
    "        Latitude of the point\n",
    "    top_left_x_coords : numpy.ndarray  shape: (number of columns,)\n",
    "        Longitude of the top-left point in each pixel\n",
    "    top_left_y_coords : numpy.ndarray  shape: (number of rows,)\n",
    "        Latitude of the top-left point in each pixel\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    lon_idx : int\n",
    "        Column index\n",
    "    lat_idx : int\n",
    "        Row index\n",
    "    \"\"\"\n",
    "    lon_idx = np.where(top_left_x_coords < lon)[0][-1]\n",
    "    lat_idx = np.where(top_left_y_coords > lat)[0][-1]\n",
    "    return lon_idx, lat_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this illustrates how you can read the nightlight image\n",
    "raster_file = 'data/nighttime_image/F182010.v4d_web.stable_lights.avg_vis.tif'\n",
    "x_size, top_left_x_coords, top_left_y_coords, centroid_x_coords, centroid_y_coords, bands_data = read_raster(raster_file)\n",
    "\n",
    "# save the result in compressed format - see https://docs.scipy.org/doc/numpy/reference/generated/numpy.savez.html\n",
    "np.savez('nightlight.npz', top_left_x_coords=top_left_x_coords, top_left_y_coords=top_left_y_coords, bands_data=bands_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Your code here\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Fit a model of wealth as a function of nightlights\n",
    "- **INPUT**: \n",
    " - `DHS_nightlights.csv`, from Step 3.1\n",
    "- **OUTPUT**: \n",
    " - R^2 of model\n",
    " \n",
    "Above, you fit a regression line to illustrate the relationship between cluster average wealth and corresponding cluster nightlights. Now, use [cross-validation](https://en.wikipedia.org/wiki/Cross-validation_%28statistics%29) to get a better sense of out of sample accuracy.\n",
    "\n",
    "There are two options for this. The basic way, for those new to machine learning, is to randomly divide your dataset into a training and a test dataset. Randomly select 80% of your clusters and fit a model of cluster-average DHS wealth (your response/dependent variable) on nightlights (your predictor/independent variables). You can use a regression or any other model you prefer. Then, use that model to predict the wealth of the remaining 20% of your data, and compare the predicted values to the actual values, and report the R^2 on these 20%.\n",
    "\n",
    "The preferred way is to use 10-fold cross-validation, where you repeat the above procedure 10 times, so that you have 10 different and non-overlapping test sets. Then, you report the cross-validated R^2 of your model (i.e., the average R^2 of your 10 test folds).\n",
    "\n",
    "Hints:\n",
    " - The scikit learn library has built-in functions for [cross-validation](http://scikit-learn.org/stable/modules/cross_validation.html) that make this quite easy.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "#\n",
    "# Your code here\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Download daytime satellite imagery \n",
    "- **INPUT**: \n",
    " - Google Maps API key\n",
    " - `Sector_Boundary_2012.shp`: Rwandan shapefile\n",
    "- **OUTPUT**: \n",
    " - Thousands of satellite images (store in directory `google_image/`)\n",
    "\n",
    "We will use the Google Static Maps API to download satellite images. Refer [Google Static Maps introduction](https://developers.google.com/maps/documentation/static-maps/intro) and [Google Static Maps API Usage Limits](https://developers.google.com/maps/documentation/static-maps/usage-limits). You must apply for an API key before downloading. ** Note that it may take you several days to download the required images, so start early!**\n",
    "\n",
    "Download the images from Google at zoom level 16 (pixel resolution is about 2.5m). Set the image size to be 400 pixels X 400 pixels, so that each image you download will cover 1 square kilometer. In this way, each daytime image you download will correspond to a single pixel from the nighttime imagery from Step 1 above.\n",
    "\n",
    "Hints:\n",
    " - You will need to tell Google the locations for which you wish to download images. One way to do this is to use a [shapefiles](https://en.wikipedia.org/wiki/Shapefile) that specifies the borders of Rwanda. We have provided this shapefile (`Sector_Boundary_2012.shp`) as well as a helper function to read in the shapefile.\n",
    " - You can organize the files however you like. However, for later analysis (Steps 6 and beyond), it may help if you organize these daytime images into 64 folders, with one folder indicating the nightlight intensity of the pixel corresponding to the daytime image. In other words, if you download a daytime image for which the corresponding nighttime pixel has value 32, store that daytime image in a folder labeled '32'. This way, all the satellite images within each folder will have the same nightlight intensity. The file name is columnIndex_rowIndex.jpg, in which row index and column index are the index in the nightlight image (See the diagram below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](figure/data_description.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function to read a shapefile\n",
    "def get_shp_extent(shp_file):\n",
    "    \"\"\"\n",
    "    Function\n",
    "    --------\n",
    "    get_shp_extent\n",
    "\n",
    "    Given a shapefile, get the extent (boundaries)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    shp_file : string\n",
    "        Path to the shapefile\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    extent : tuple\n",
    "        Boundary location of the shapefile (x_min, x_max, y_min, y_max)\n",
    "    \"\"\"\n",
    "    inDriver = ogr.GetDriverByName(\"ESRI Shapefile\")\n",
    "    inDataSource = inDriver.Open(inShapefile, 0)\n",
    "    inLayer = inDataSource.GetLayer()\n",
    "    extent = inLayer.GetExtent()\n",
    "    # x_min_shp, x_max_shp, y_min_shp, y_max_shp = extent\n",
    "    return extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Helper functions to download images from Google Maps API\n",
    "\n",
    "from retrying import retry\n",
    "\n",
    "@retry(wait_exponential_multiplier=1000, wait_exponential_max=3600000)\n",
    "def save_img(url, file_path, file_name):\n",
    "    \"\"\"\n",
    "    Function\n",
    "    --------\n",
    "    save_img\n",
    "\n",
    "    Given a url of the map, save the image\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : string\n",
    "        URL of the map from Google Map Static API\n",
    "    file_path : string\n",
    "        Folder name of the map\n",
    "    file_name : string\n",
    "        File name\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    a = urllib.urlopen(url).read()\n",
    "    b = cStringIO.StringIO(a)\n",
    "    image = ndimage.imread(b, mode='RGB')\n",
    "    # when no image exists, api will return an image with the same color. \n",
    "    # and in the center of the image, it said'Sorry. We have no imagery here'.\n",
    "    # we should drop these images if large area of the image has the same color.\n",
    "    if np.array_equal(image[:,:10,:],image[:,10:20,:]):\n",
    "        pass\n",
    "    else:\n",
    "        misc.imsave(file_path + file_name, image[50:450, :, :])\n",
    "\n",
    "# Now read in the shapefile for Rwanda and extract the edges of the country\n",
    "inShapefile = \"data/shp/Sector_Boundary_2012/Sector_Boundary_2012.shp\"\n",
    "x_min_shp, x_max_shp, y_min_shp, y_max_shp = a\n",
    "\n",
    "left_idx, top_idx = get_cell_idx(x_min_shp, y_max_shp, top_left_x_coords, top_left_y_coords)\n",
    "right_idx, bottom_idx = get_cell_idx(x_max_shp, y_min_shp, top_left_x_coords, top_left_y_coords)\n",
    "\n",
    "key = 'YOUR_GOOGLE_MAP_API_KEY'\n",
    "m = 1\n",
    "for i in xrange(left_idx, right_idx + 1):\n",
    "    for j in xrange(top_idx, bottom_idx + 1):\n",
    "        lon = centroid_x_coords[i]\n",
    "        lat = centroid_y_coords[j]\n",
    "        url = 'https://maps.googleapis.com/maps/api/staticmap?center=' + str(lat) + ',' + \\\n",
    "               str(lon) + '&zoom=16&size=400x500&maptype=satellite&key=' + key\n",
    "        lightness = bands_data[j, i, 0]\n",
    "        file_path = 'google_image/' + str(lightness) + '/'\n",
    "        if not os.path.isdir(file_path):\n",
    "            os.makedirs(file_path)\n",
    "        file_name = str(i) + '_' + str(j) +'.jpg'\n",
    "        save_img(url, file_path, file_name)\n",
    "        if m % 100 == 0:\n",
    "            print m\n",
    "        m += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Test whether basic features of daytime imagery can predict wealth\n",
    "In step 3, you tested whether nightlight imagery could predict the wealth of Rwandan villages. You will now test whether daytime imagery can predict village wealth. Start by extracting simple metrics from the daytime imagery; in step 6 you will use more sophsticated methods to engineer these features from the images. **You don't need to do this step if you are able to do step 6.**\n",
    "\n",
    "## 5.1. Extract \"basic\" features from daytime imagery\n",
    "- **INPUT**: \n",
    " - `google_image/...`: Raw images, from Step 4\n",
    "- **OUTPUT**: \n",
    " - `google_image_features_basic.csv`: Image features \n",
    "\n",
    "Convert the raw data from the satellite imagery into a set of features that can be used in a machine learning algorithm. A simple way to do this is to take the raw R/G/B values for each pixel and average them for the image. Thus, if an image has 100 pixels, you will have an average R value, an average G value, and an average B value. Create more features by also computing the min, max, median, and standard deviation of R, G, and B for each image. This process will convert each image into a vector of 15 features.\n",
    "\n",
    "Feel free to be creative if you wish to generate additional features from the imagery -- this is similar to the process described in section 2.3 of the paper's supplementary materials. But don't waste too much time, and don't expect these features to be terribly useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Your code here\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Merge daytime images with DHS data\n",
    "\n",
    "- **INPUT**: \n",
    " - `google_image_features_basic.csv`: Satellite imagery features, from Step 5.1\n",
    " - `rwanda_cluster_avg_asset_2010.csv`: DHS cluster averages, from Step 2\n",
    "- **OUTPUT**: Merged datasets\n",
    " - `data/model/DHS_daytime.csv`: Merged dataset with 492 rows, and 16 columns (one indicates average cluster wealth, 15 daytime image features)\n",
    "\n",
    "Now that you have feature vectors for each image, you should merge these with the DHS data indicated average cluster wealth. Follow a similar procedure as you did with 3.1, i.e., determine which image feature vectors are associated with each cluster, and then calculate, for each cluster, the average value of each feature.\n",
    "\n",
    "Save your output as `DHS_daytime.csv` and check that it is roughly the same as the file we have provided. There may be slight differences if you chose to calculate a different set of features than those described in 5.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Your code here\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Fit a model of wealth as a function of basic daytime features\n",
    "- **INPUT**: \n",
    " - `data/model/DHS_daytime.csv`, from Step 5.2\n",
    "- **OUTPUT**: \n",
    " - R^2 of model\n",
    " \n",
    "As in 3.2, use 10-fold cross-validation to fit a model of cluster-level DHS wealth (your response/dependent variable) as a function of the nightlights data (your predictor/independent variables). Since you have a reasonably large number of predictor variables, you should use a model that incorporates some form of regularization (e.g., ridge regression, lasso regression, or a tree-based method).  Report the cross-validated R^2 of your model (i.e., the average R^2 of your 10 test folds).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Your code here\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Extract features from daytime imagery using deep learning libraries\n",
    "\n",
    "This is where things get interesting. Above, you have seen that the RGB features of the daytime images are not great at predicting cluster average wealth (why not?). Now, you will use existing libraries to extract more meaningful features from the daytime imagery, similar to what is shown in Fig. 2 of the paper.\n",
    "\n",
    "## 6.1. Use the keras library to use a basic CNN to extract features of the daytime images \n",
    " \n",
    "- **INPUT**: \n",
    " - `google_image/...`: Raw images, from Step 4\n",
    "- **OUTPUT**: \n",
    " - `google_image_features_cnn.csv`: Image features \n",
    "\n",
    "Begin by using a Convolutional Neural Network that has been pre-trained on ImageNet to extract features from the images. We recommend using the [`Keras` library](https://keras.io/), which provides a very straightforward interface to [TensorFlow](https://www.tensorflow.org/).\n",
    "\n",
    "Hints:\n",
    " - This [short intro](https://github.com/fchollet/deep-learning-models/blob/master/README.md) will help you get started with extracting features from the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Your code here\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2. Test whether these new features of satellite imagery can predict wealth\n",
    "- **INPUT**: \n",
    " - `google_image_features_cnn.csv`: Satellite imagery features, from Step 6.1\n",
    " - `rwanda_cluster_avg_asset_2010.csv`: DHS cluster averages, from Step 2\n",
    "- **OUTPUT**: \n",
    " - `data/model/DHS_daytime.csv`: Merged dataset with 492 rows, and 4097 columns (one indicates average cluster wealth, 4096 CNN-based features)\n",
    " - R^2 of model\n",
    " \n",
    "Calculate the average value of each feature for each of the DHS clusters. As in Step 3.1 and 5.2, you will want to aggregate over images near the cluster centroid by taking the average value for each feature. Create a scatterplot showing the relationship between average cluster wealth (y-axis) and the first principal component of all of your image features (x-axis) - in other words, run PCA on your 4096 image features and plot the first PC on the x-axis. Your scatterplot should have one dot for each of the 492 DHS clusters.\n",
    "\n",
    "Use 10-fold cross-validation to fit a model of cluster-level DHS wealth (your response/dependent variable) as a function of the \"deep\" features (your predictor/independent variables). Use a model that incorporates some form of regularization (e.g., ridge regression, lasso regression, or a tree-based method).  Report the cross-validated R^2 of your model (i.e., the average R^2 of your 10 test folds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "#\n",
    "# Your code here\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Extra Credit 1: Replicate final model and results of Jean et al (2016)\n",
    "\n",
    "The only thing missing at this point is the \"transfer learning\" step. In other words, instead of using the image features extracted by the CNN directly, we want to retrain the CNN to predict nightlights from daytime imagery, and use those features, which presumably are more appropriate to our final prediction task.\n",
    "\n",
    "## 7.1. Use the nightlights to retrain the CNN and extract features\n",
    "\n",
    "- **INPUT**: \n",
    " - `google_image/...`: Raw images, from Step 4\n",
    "- **OUTPUT**: \n",
    " - `google_image_features_cnn_retrained.csv`: Image features \n",
    "\n",
    "Following the approach used in the paper, first divide your daytime images into three groups, corresponding to images where the corresponding night-lights pixel is dim, medium, or bright. Use these values to define your groups: [0, 3), [3, 35), [35, 64). We have given you the code to do this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Your code here\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. Test whether \"deep\" features of satellite imagery can predict wealth\n",
    "- **INPUT**: \n",
    " - `google_image_cnn/...`: Satellite images from 7.1\n",
    "- **OUTPUT**: \n",
    " - `data/model/DHS_CNN.csv`: Merged dataset with 492 rows, and 4097 columns (one indicates average cluster wealth, 4096 CNN features)\n",
    " - R^2 of model\n",
    "\n",
    "Repeat 6.2, except this time use the features generated from 7.1, i.e., the features that have been constructed after transfer learning. As in 6.2, show a scatterplot of the relationship between average cluster wealth (y-axis) and the first principal component of your image features. Then, report the cross-validated R^2 of your model (i.e., the average R^2 of your 10 test folds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Your code here\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Extra Credit 2: Construct a high-resolution map of the distribution of predicted wealth\n",
    "- **INPUT**: \n",
    " - Model, image features (data/model/features_all_predictimage_location.csv)\n",
    "- **OUTPUT**: \n",
    " - Map ('poverty_mapping.tiff')\n",
    " \n",
    "Choose your favorite model from the three daytime-based models that you have trained above: 5.3 (basic daytime features), 6.2 (deep daytime features), or 7.2 (transfer-learned daytime features). Use this model to calculate the predicted wealth of every one of your original images. Create a heatmap showing the distribution of predicted wealth in Rwanda. With any luck, it will look something like this:\n",
    "<img src=\"figure/pmap.png\" alt=\"Map\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Your code here\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
